---
title: Sphere
date: 2023-04-21 15:10:15
permalink: /pages/10203/
sidebar: false
article: false
---
::: note 开源地址
Github：[https://github.com/facebookresearch/Sphere](https://github.com/facebookresearch/Sphere/)
::: 
# Sphere

[![img](https://github.com/facebookresearch/Sphere/raw/main/sphere_logo.png)](https://github.com/facebookresearch/Sphere/blob/main/sphere_logo.png)

# 关于

在我们的论文[*The Web Is Your Oyster - Knowledge-Intensive NLP against a Very Large Web Corpus*](https://arxiv.org/abs/2112.09924)中，我们建议使用 Web 语料库作为一个通用的、未经管理的和非结构化的知识源，同时用于多个 KI-NLP 任务。

我们利用开放的网络语料库加上强大的检索基线，而不是黑盒的商业搜索引擎——这种方法促进了透明和可重复的研究，并为未来的研究开辟了一条道路，将针对人类优化的搜索引擎与为神经网络设计的检索解决方案进行比较网络。我们使用 CCNet 的一个子集，[覆盖](https://github.com/facebookresearch/cc_net)134M 文档，分成 906M 段落作为我们称之为**Sphere**的网络语料库。

[在这个存储库中，我们为与Pyserini](https://github.com/castorini/pyserini)兼容的稀疏检索基线以及与[分布式 faiss](https://github.com/facebookresearch/distributed-faiss)兼容的最佳密集模型开放了 Sphere 的源索引。我们还提供了有关如何使用[KILT](https://github.com/facebookresearch/KILT) API 评估标准和新引入的检索指标的检索性能的说明。

## 参考

如果您在研究中使用此存储库的内容，请引用以下内容：

```
@article{DBLP:journals/corr/abs-2112-09924,
  author    = {Aleksandra Piktus and Fabio Petroni
               and Vladimir Karpukhin and Dmytro Okhonko
               and Samuel Broscheit and Gautier Izacard
               and Patrick Lewis and Barlas Oguz
               and Edouard Grave and Wen{-}tau Yih
               and Sebastian Riedel},
  title     = {The Web Is Your Oyster - Knowledge-Intensive {NLP} against a Very
               Large Web Corpus},
  journal   = {CoRR},
  volume    = {abs/2112.09924},
  year      = {2021},
  url       = {https://arxiv.org/abs/2112.09924},
  eprinttype = {arXiv},
  eprint    = {2112.09924},
  timestamp = {Tue, 04 Jan 2022 15:59:27 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2112-09924.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
```

## 安装

```
git clone git@github.com:facebookresearch/Sphere.git
cd Sphere
conda create -n sphere -y python=3.7 && conda activate sphere
pip install -e .
```

## 索引下载

我们开源预先构建的 Sphere 索引：

- Pyserini 兼容的稀疏 BM25 索引：[sphere_sparse_index.tar.gz](https://dl.fbaipublicfiles.com/sphere/sphere_sparse_index.tar.gz) - 775.6 GiB
- 一个分布式 faiss 兼容的密集 DPR 索引：[sphere_sparse_index.tar.gz](https://dl.fbaipublicfiles.com/sphere/sphere_dense_index.tar.gz) - 1.2 TiB

您可以直接下载和解压相应的索引文件，例如通过以下浏览器 `wget`：

```
mkdir -p faiss_index

wget -P faiss_index https://dl.fbaipublicfiles.com/sphere/sphere_sparse_index.tar.gz
tar -xzvf faiss_index/sphere_sparse_index.tar.gz -C faiss_index

wget -P faiss_index https://dl.fbaipublicfiles.com/sphere/sphere_dense_index.tar.gz
tar -xzvf faiss_index/sphere_dense_index.tar.gz -C faiss_index
```

# 用[KILT进行评估](https://github.com/facebookresearch/KILT)

我们实现了论文中介绍的检索指标：

- `answer-in-context@k`, _
- `answer+entity-in-context@k`, _
- 以及 `entity-in-input`消融指标

在 KILT 存储库中。按照以下说明执行和评估对稀疏和密集球体索引的 KILT 任务的检索。

## KILT 依赖项

```shell
pip install -e git+https://github.com/facebookresearch/KILT#egg=KILT
```

下载 KILT 数据。查看[KILT 存储](https://github.com/facebookresearch/KILT#download-the-data)库中的说明以获取更多详细信息。

```shell
mkdir -p data
python src/kilt/scripts/download_all_kilt_data.py
python src/kilt/scripts/get_triviaqa_input.py
```

## 密集指数

### 安装依赖项

```shell
pip install -e git+https://github.com/facebookresearch/distributed-faiss#egg=distributed-faiss
pip install -e git+https://github.com/facebookresearch/DPR@multi_task_training#egg=DPR
pip install spacy==2.1.8
python -m spacy download en
```

### 启动 `distributed-faiss`服务器

更多细节[在这里](https://github.com/facebookresearch/distributed-faiss#launching-servers-with-submitit-on-slurm-managed-clusters)。

```shell
python src/distributed-faiss/scripts/server_launcher.py \
    --log-dir logs \
    --discovery-config faiss_index/disovery_config.txt \
    --num-servers 32 \
    --num-servers-per-node 4 \
    --timeout-min 4320 \
    --save-dir faiss_index/ \
    --mem-gb 500 \
    --base-port 13034 \
    --partition dev &
```

### 下载资产

- DPR_web 模型：[dpr_web_biencoder.cp](http://dl.fbaipublicfiles.com/sphere/dpr_web_biencoder.cp)
- 配置文件：[dpr_web_sphere.yaml](https://dl.fbaipublicfiles.com/sphere/dpr_web_sphere.yaml)

```shell
mkdir -p checkpoints
wget -P checkpoints http://dl.fbaipublicfiles.com/sphere/dpr_web_biencoder.cp

mkdir -p configs
wget -P configs https://dl.fbaipublicfiles.com/sphere/dpr_web_sphere.yaml
```

`dpr_web_sphere.yaml`随后更新配置文件中的以下字段：

```shell
n_docs: 100 # the number of documents to retrieve per query
model_file: checkpoints/dpr_web_biencoder.cp # path to the downloaded model file
rpc_retriever_cfg_file: faiss_index/disovery_config.txt # path to the discovery config file used when launching the distributed-faiss server
rpc_index_id: dense # the name of the folder contaning dense index partitions
```

### 执行检索

为了从密集索引中执行检索，您首先需要启动分布式faiss 服务器，如上所述。您可以通过修改相应的配置文件来控制执行检索的 KILT 数据集，例如 `src/kilt/configs/dev_data.json`.

```shell
python src/kilt/scripts/execute_retrieval.py \
    --model_name dpr_distr \
    --model_configuration configs/dpr_web_sphere.yaml \
    --test_config src/kilt/kilt/configs/dev_data.json \
    --output_folder output/dense/
```

## 稀疏索引

### 安装依赖项

我们的稀疏索引依赖于 Pyserini，因此需要在机器上[安装 Java 11](https://github.com/castorini/pyserini#installation)。

```shell
pip install jnius
pip install pyserini==0.9.4.0
```

接下来，下载以下文件：

- 配置文件：[bm25_sphere.json](https://dl.fbaipublicfiles.com/sphere/bm25_sphere.json)

```shell
mkdir -p configs
wget -P configs https://dl.fbaipublicfiles.com/sphere/bm25_sphere.json
```

`bm25_sphere.json`随后更新配置文件中的以下字段：

```shell
"k": 100, # the number of documents to retrieve per query
"index": "faiss_index/sparse", # path to the unpacked sparse BM25 index
```

### 执行检索

```
python src/kilt/scripts/execute_retrieval.py \
    --model_name bm25 \
    --model_configuration configs/bm25_sphere.json \
    --test_config src/kilt/kilt/configs/dev_data.json \
    --output_folder output/sparse/
```

## 检索评估

```shell
python src/kilt/kilt/eval_retrieval.py \
    output/$index/$dataset-dev-kilt.jsonl \ # retrieval results - the output of running eval_retrieval.py
    data/$dataset-dev-kilt.jsonl \ # gold KILT file (available for download in the KILT repo)
    --ks="1,20,100"
```

# 独立密集索引使用情况

安装并启动 `distributed-faiss`. 有关 `distributed-faiss`服务器的更多详细信息，请[点击此处](https://github.com/facebookresearch/distributed-faiss#launching-servers-with-submitit-on-slurm-managed-clusters)。

```shell
pip install -e git+https://github.com/facebookresearch/distributed-faiss#egg=distributed-faiss
python src/distributed-faiss/scripts/server_launcher.py \
    --log-dir logs/ \
    --discovery-config faiss_index/disovery_config.txt \
    --num-servers 32 \
    --num-servers-per-node 4 \
    --timeout-min 4320 \
    --save-dir faiss_index/ \
    --mem-gb 500 \
    --base-port 13034 \
    --partition dev &
```

## 独立客户端示例

对于查询 Sphere 密集索引的最小工作示例，我们建议通过 `transformers`API 与 DPR 模型进行交互。为此，请安装依赖项：

```shell
pip install transformers==4.17.0
```

使用带有转换器 API 的 DPR 检查点需要重新格式化原始检查点。您可以在 `transformers`此处下载并解压兼容的 DPR_web 查询编码器：

- [dpr_web_query_encoder_hf.tar.gz](https://dl.fbaipublicfiles.com/sphere/dpr_web_query_encoder_hf.tar.gz)

```shell
mkdir -p checkpoints
wget -P checkpoints https://dl.fbaipublicfiles.com/sphere/dpr_web_query_encoder_hf.tar.gz
tar -xzvf checkpoints/dpr_web_query_encoder_hf.tar.gz -C checkpoints/
```

或者，您可以使用可用脚本[`dpr_web_biencoder.cp`](http://dl.fbaipublicfiles.com/sphere/dpr_web_biencoder.cp)自己转换模型。

然后您可以运行交互式演示：

```shell
python scripts/sphere_client_demo_hf.py \
    --encoder checkpoints/dpr_web_query_encoder_hf \
    --discovery-config faiss_index/disovery_config.txt \
    --index-id dense
```

# 执照

`Sphere`在 CC-BY-NC 4.0 许可下发布。有关详细信息，请参阅 `LICENSE`文件。